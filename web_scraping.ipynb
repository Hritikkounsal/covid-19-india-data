{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import requests \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"20%\"><strong>Date</strong></th>\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"20%\"><strong>DATE</strong></th>\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"20%\"><strong>DATE</strong></th>\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"20%\"><strong>DATE</strong></th>\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"20%\"><strong>DATE</strong></th>\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#ff0000\">\n",
      "<th align=\"centre\" colspan=\"2\"><strong>LATEST UPDATES</strong></th>\n",
      "</tr>\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"centre\" width=\"20%\"><strong>DATE</strong></th>\n",
      "<th align=\"centre\" width=\"80%\"><strong>TITLE</strong></th>\n",
      "</tr>\n",
      "</thead>, <thead class=\"thead-dark\">\n",
      "<tr bgcolor=\"#f8f8f8\">\n",
      "<th align=\"left\" width=\"47\"><strong>S. No.</strong></th>\n",
      "<th align=\"left\" width=\"83\"><strong>Name of State / UT</strong></th>\n",
      "<th align=\"left\" width=\"91\"><strong>Total Confirmed cases (Indian National)</strong></th>\n",
      "<th align=\"left\" width=\"90\"><strong>Total Confirmed cases ( Foreign National )</strong></th>\n",
      "<th align=\"left\" width=\"83\"><strong>Cured/<br/>Discharged/Migrated</strong></th>\n",
      "<th align=\"left\" width=\"83\"><strong>Death</strong></th>\n",
      "</tr>\n",
      "</thead>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-af0947c59284>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mthead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'thead'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tbody'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2079\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 2081\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "# web scrapping\n",
    "\n",
    "link = 'https://www.mohfw.gov.in/'\n",
    "req = requests.get(link)\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "thead = soup.find_all('thead')\n",
    "print(thead)\n",
    "head = thead.find_all('tr')\n",
    "\n",
    "tbody = soup.find_all('tbody')[2]\n",
    "body = tbody.find_all('tr')\n",
    "\n",
    "# print(rows)\n",
    "\n",
    "head_rows = []\n",
    "body_rows = []\n",
    "\n",
    "for tr in head:\n",
    "    td = tr.find_all(['th', 'td'])\n",
    "    row = [i.text for i in td]\n",
    "    head_rows.append(row)\n",
    "    \n",
    "for tr in body:\n",
    "    td = tr.find_all(['th', 'td'])\n",
    "    row = [i.text for i in td]\n",
    "    body_rows.append(row)\n",
    "    \n",
    "print(head_rows)\n",
    "    \n",
    "df_bs = pd.DataFrame(body_rows[:len(body_rows)-1], columns=head_rows[0])\n",
    "    \n",
    "df_bs.drop('S. No.', axis=1, inplace=True)\n",
    "df_bs.head(36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date-time information\n",
    "# ---------------------\n",
    "\n",
    "now  = datetime.now()\n",
    "df_bs['Date'] = now.strftime(\"%m/%d/%Y\") \n",
    "df_bs['Date'] = pd.to_datetime(df_bs['Date'], format='%m/%d/%Y')\n",
    "df_bs.head(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs['Name of State / UT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude and longitude information\n",
    "# ----------------------------------\n",
    "\n",
    "lat = {'Delhi':28.7041,\n",
    "       'Haryana':29.0588,\n",
    "       'Kerala':10.8505,\n",
    "       'Rajasthan':27.0238,\n",
    "       'Telengana':18.1124,\n",
    "       'Uttar Pradesh':26.8467,\n",
    "       'Ladakh':34.2996,\n",
    "       'Tamil Nadu':11.1271,\n",
    "       'Jammu and Kashmir':33.7782,\n",
    "       'Punjab':31.1471,\n",
    "       'Karnataka':15.3173,\n",
    "       'Maharashtra':19.7515,\n",
    "       'Andhra Pradesh':15.9129, \n",
    "       'Odisha':20.9517, \n",
    "       'Uttarakhand':30.0668, \n",
    "       'West Bengal':22.9868, \n",
    "       'Puducherry': 11.9416, \n",
    "       'Chandigarh': 30.7333, \n",
    "       'Chhattisgarh':21.2787, \n",
    "       'Gujarat': 22.2587, \n",
    "       'Himachal Pradesh': 31.1048, \n",
    "       'Madhya Pradesh': 22.9734, \n",
    "       'Bihar': 25.0961}\n",
    "\n",
    "long = {'Delhi':77.1025,\n",
    "        'Haryana':76.0856,\n",
    "        'Kerala':76.2711,\n",
    "        'Rajasthan':74.2179,\n",
    "        'Telengana':79.0193,\n",
    "        'Uttar Pradesh':80.9462,\n",
    "        'Ladakh':78.2932,\n",
    "        'Tamil Nadu':78.6569,\n",
    "        'Jammu and Kashmir':76.5762,\n",
    "        'Punjab':75.3412,\n",
    "        'Karnataka':75.7139,\n",
    "        'Maharashtra':75.7139,\n",
    "        'Andhra Pradesh':79.7400, \n",
    "        'Odisha':85.0985, \n",
    "        'Uttarakhand':79.0193, \n",
    "        'West Bengal':87.8550, \n",
    "        'Puducherry': 79.8083, \n",
    "        'Chandigarh': 76.7794, \n",
    "        'Chhattisgarh':81.8661, \n",
    "        'Gujarat': 71.1924, \n",
    "        'Himachal Pradesh': 77.1734, \n",
    "        'Madhya Pradesh': 78.6569, \n",
    "        'Bihar': 85.3131}\n",
    "\n",
    "df_bs['Latitude'] = df_bs['Name of State / UT'].map(lat)\n",
    "df_bs['Longitude'] = df_bs['Name of State / UT'].map(long)\n",
    "\n",
    "df_bs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data\n",
    "# -----------\n",
    "\n",
    "file_name = now.strftime(\"%Y_%m_%d\")+'.csv'\n",
    "file_loc = 'C:\\\\Users\\\\imdevskp\\\\Desktop\\\\covid_india\\\\.day_by_day_data\\\\'\n",
    "df_bs.to_csv(file_loc + file_name, index=False)\n",
    "\n",
    "df_bs.head(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls C:\\Users\\imdevskp\\Desktop\\covid_india\\.day_by_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete data\n",
    "\n",
    "loc = \"C:\\\\Users\\\\imdevskp\\\\Desktop\\\\covid_india\\\\.day_by_day_data\\\\\"\n",
    "\n",
    "files = glob.glob(loc+'2020*.csv')\n",
    "dfs = []\n",
    "for i in files:\n",
    "    df_temp = pd.read_csv(i)\n",
    "    df_temp = df_temp.rename(columns={'Cured':'Cured/Discharged'})\n",
    "    df_temp = df_temp.rename(columns={'Cured/Discharged':'Cured/Discharged/Migrated'})\n",
    "    dfs.append(df_temp)\n",
    "    \n",
    "# print(dfs)\n",
    "\n",
    "complete_data = pd.concat(dfs, ignore_index=True).sort_values(['Date'], ascending=True).reset_index(drop=True)\n",
    "complete_data['Date'] = pd.to_datetime(complete_data['Date'])\n",
    "complete_data = complete_data.sort_values(['Date', 'Name of State / UT']).reset_index(drop=True)\n",
    "\n",
    "cols = ['Total Confirmed cases (Indian National)', 'Total Confirmed cases ( Foreign National )', \n",
    "              'Cured/Discharged/Migrated', 'Death']\n",
    "\n",
    "complete_data[cols] = complete_data[cols].fillna(0).astype('int')\n",
    "\n",
    "# complete_data.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['Name of State / UT'].replace('Chattisgarh', 'Chhattisgarh', inplace=True)\n",
    "complete_data['Name of State / UT'].replace('Pondicherry', 'Puducherry', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['Name of State / UT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(complete_data['Name of State / UT'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.to_csv('complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
